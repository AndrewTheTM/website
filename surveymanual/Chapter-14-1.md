---
title: 'Household Survey Procedures And Measures For Further Research'
categories:
  - Survey Manual
---
### Chapter-14-1

**CHAPTER 14.0 HOUSEHOLD SURVEY PROCEDURES AND MEASURES FOR FURTHER RESEARCH**

*Note: Significant components of this chapter come from Chapter 4 of the NCHRP Report.  Material has been reviewed and updated by Matthew Roorda, Cristina Pronello and Casper Chorus.***14.1  D-11: GPS Surveys**

There is growing interest in the use of GPS devices to collect data on sub-samples of households in household travel surveys. GPS is capable of providing very precise information about the locations to and from which people travel, the times of their travel, the routes used, and even the traffic conditions along the route of travel at the time of travel. At present, this is largely an experimental procedure although it is moving rapidly forward as a mainstream activity in household travel surveys.  There are well over 20 ongoing surveys in Europe and North America that have a GPS component at the time of this report, involving both personal GPS devices and in-vehicle GPS devices.

As a typical example of a personal GPS survey, the 2007-08 French National Travel Survey gave a sub-sample of approximately 800 volunteers a GPS receiver (Marchal et al., 2008).  When a respondent agrees to the GPS option, the following steps are undertaken:

·   a first face-to-face interview is undertaken, in which the interviewer gives a "GPS Pack" to the respondent (older than 17), and explains how to use the equipment;

·   the respondent travels and the unit records trips;

·   at a second face-to-face interview the respondent returns the "GPS Pack" to the interviewer,  the interviewer downloads the GPS data to a laptop computer using a bluetooth transfer, a brief interview is conducted; 

·   the interviewer checks the GPS unit, reloads it; the equipment is ready for another respondent.

Vehicle-based GPS surveys are an alternative.  For example, in Italy, a GPS system has been set up on a sample of the 1% of the universe of Italian car fleet, for insurance reasons.  The system measures vehicle position and velocity every time the engine is switched on or off, and during the travel approximately every 2 km. These data have been used to study travel length distributions in different urban contexts, including Senigallia (small town), Bologna (middle town) and Roma (metropolis) (Rambaldi et al., 2007).

Clearly there is potential for defining standardized procedures and providing guidance on a number of aspects of such surveys. This includes sample sizes and methods of drawing samples, geographic and socio-demographic distribution of the sample, the number of days for which GPS data should be collected, minimum hardware specifications for the GPS devices, the use of incentives, methods for deployment of the devices, methods of return of the devices, etc. However, at this time, it is probably too early in the development of such surveys, and there is too little experience to define standardized procedures. Therefore, this is an area that should be considered as being currently out of scope, but necessary to add within the next 2 or 3 years. It also may require extensive field experimentation to develop good standardized procedures through comparative studies that clearly show which are the preferred methods. Also, as personal GPS devices (as opposed to in-vehicle GPS devices) become more practicable and available, the nature of the survey may change quite rapidly.

**14.2  I-8: SP Data**

Many recent travel surveys have included collection of stated-choice data, more commonly referred to as “stated-preference” or SP data.

This survey technique has been used often in the USA, despite criticism by several researchers (Louviere, 1984; Louviere and Timmermans, 1990; Oppewal et al., 1994; Wang, et al., 2001; Richardson, 2002). In particular, concerns about respondent burden have been raised by several authors who suggested also methods to reduce it, but, as Arentze et al. (2003) highlight, we have a limited knowledge of the effects of task complexity on the validity of response measures in stated preference and choice analysis in transport research. A methodological study on the respondent burden has been carried out by Stopher and Hensher (2000), who found that task complexity up to 32 profiles have only a marginal impact on elasticities.

Another point concerns the complexity of the choice process and the cognitive capabilities involved in it, as highlighted by Arentze et al. (2003). The authors deal with the complexity issue citing studies from different authors: the alternative approaches including hierarchical information integration, originally developed for stated preference models (Louviere, 1984), later extended to stated choice models (Timmermans, 1989; Louviere and Timmermans, 1990), integrated choice experiments (Oppewal et al., 1994), pairwise conjoint analysis (Wang, et al., 2001), and adaptive stated preference analysis (Richardson, 2002). Richardson (2001) reminds that studies carried out in transport research (Hensher, 2001) put in evidence a lack of agreement over the respondent capability in dealing complex SC experiments, also if the same author (Louviere and Hensher, 2000) “found no evidence to flatly reject specific design strategies”.

Nevertheless the above considerations, in according to Richardson (2001), the understanding and answering to complex SP questions do not seem to have been systematically assessed using cognitive pre-testing techniques, as has been done with many other types of survey question (e.g. Forsyth & Lessler, 1991; Timmermans, 1993; Bickart & Felcher, 1996; DeMaio & Rothgeb, 1996)”. Thus we have to look at other areas of survey design, different from transport, to analyse the results of such cognitive pre-testing. Differently from Stopher and Hensher (2000), Orme (1997) and before Miller (1956) reported the difficulty recorded by psychologists when people have to process more than six pieces of information at the same time. 

In fact, we should remember that the choice process has been traditionally based on the random utility theory, assuming that the decision-maker has a perfect discrimination capability. Only in the last years the respondents are analysed also under a psychological point of view, taking care with the construction of the choice scenarios. In addition, to address complexity, in the last years, verbal and non-verbal language has been increasingly considered a fundamental basis for a good questionnaire design. In fact, both too many attributes, too complex words, and too wordy language describing attributes can compromise the reliability of answers. In fact, to quote Richardson (2001), “the problem with posing SP questions that are highly complex is that different people may employ very different decision rules to arrive at an answer”. A simple method for respondents to manage a choice set is needed, taking into consideration the factorial design of the combination of the attributes characterizing the scenarios. Effectively, there are no international guidelines to design SP surveys.

The major problems of such a survey, for which existing literature is limited, can be summarized as:

-  definition of pre-test explaining to respondents to which typology of survey they are facing to;

-    importance of non-verbal languages, such as use of graphics and symbols;

-    the need for contextual data to be collected at the same time;

-    length of the survey, maximum number of scenarios and choices to administer;

-    whether the order in which treatments are offered has an effect on choices;

-    univocal definition for the variables;

-    the number of attributes that can be included in the design;

-    the number of levels of each attribute that can be included;

-    how far the levels of the attributes can depart from current experience of the respondent;

-    how to administer the SP experiment—that is, by paper and pencil, on laptop computer, etc.

-  complexity of the survey in function of the methodology used to collect the data;

-    orthogonality of the SP design;

-    determination whether attribute levels should be generated in real time or can be pre-set and committed to a printed survey.

In addition, there are some survey researchers who do not believe that stated-choice experiments are valid and would argue against their use.

Hence, to develop standardized procedures for SP data, it will be necessary to undertake research on all of these issues. For the most part, this will require a battery of alternative SP survey designs to test various options in each of the bullets listed above. Several of these can be tested together; the results, in the form of some measure of the quality of the SP survey, can be analyzed through models that seek to explain differences in the quality as a function of the various design variants. At the outset this area was considered to be beyond the scope of this project; it is, therefore, up to future research to establish standards.



 



 



 



 



 



 



 



 



 



 



