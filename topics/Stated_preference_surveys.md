---
title: "Stated-preference surveys"
categories:
  - Needs Review
  - Travel Surveys
---

Note: This material comes from the Travel Survey Manual Chapter 21. It was originally composed by Gonçalo Correia and Mark Bradley, drawing also from the FHWA’s Travel Survey Manual’s Chapter 13.

## Introduction

This chapter explains the basic theory of Stated-Preference (SP) surveys, with emphasis on transport mode choices, and provides some examples from recent practice. The chapter begins by distinguishing SP surveys from related survey experiments. Then, the four main stages of SP experiment design are described, focusing on the construction of choice alternatives and how these are presented to the respondents. The Chapter continues with discrete choice model theory and calibration using SP data sets, with emphasis on the binary logit model, and concludes with some specific examples.

In general transportation planning, surveys are meant to capture travelers’ current travel behavior. For instance, one is interested in knowing the actual mode a traveler is using, actual travel times, destinations, and so forth. This is known as Revealed Preference (RP) data, as the traveler is currently experiencing that behavior and making a choice based on his or her knowledge of the available travel options. Another type of data is based on Stated Responses (SR), in which hypothetical situations are presented to the respondents, who are then asked to choose based on the given attributes for each alternative, without necessarily experiencing them in real situations. SP is a very popular sub-class of SR methods, focused on estimating the utility function for alternatives (Lee-Gosselin 1995). Other question types in this class are stated intentions, stated tolerance, stated adaptation, and stated prospect, as discussed later in this chapter.

SR surveys offer a great advantage for overcoming the problem of the “new option”, whereby an analyst seeks to forecast the use of a new alternative (such as high-speed rail), particularly when the new option is very different from existing alternatives with which the respondent is familiar. The use of a new alternative is not reflected in RP data collected on choices made in real markets.

Another aspect where RP data often fails is that one is not able to correctly identify the alternatives that were not chosen. The decision maker faces options while having imperfect information, and not knowing all his/her alternatives. Other times the decision maker will only have access to attribute information on the chosen alternatives, e.g. having information on the current automobile trip and no information on all public transport alternatives possible in the area.

As noted above, the most common type of SR question is the SP variety, where the respondent is asked to chose, rank or rate different alternatives based on their attributes (e.g., travel time, travel cost, and wait time), thus giving information on the way the choice is made. For a choice-based SP survey one is aiming to get a choice on the preferred alternative. In a ranking experiment the respondent has to rank the alternatives in order of preference. In a rating experiment each alternatives must be classified using a scale which measures its attractiveness to the respondent. An example of a choice-based experiment is shown in Figure 21.1, where the objective is to understand how respondents make the choice between the automobile and bus alternative. Because each alternative is identified with its name, Automobile and Bus, this is called a “labeled” experiment and allows analysts to calibrate alternative-specific constants for such clear labels in DCMs. An alternative type of “non-labeled” experiment might simply seek to study bus users’ preferences among various service features, and ask respondents to choose between various bus service descriptions that differ only in terms of the service attributes, but have no overall distinguishing feature.

#### Figure 21.1  Example of a Labeled Stated-Preference Experiment

There are at least four other types of SR surveys: Stated Intentions, Stated Tolerance, Stated Adaptation and Stated , as described below (and as extracted from Lee-Gosselin (1995)):

**Stated Intentions**: This is perhaps the simplest form of SR question. Typically one or two new choice alternatives are described, and respondents are asked if they would use the new alternative or not, in the form of a binary yes or no question (or they may be asked to rate how likely they would be to use the alternative). Such questions may be useful to get a simple overall indication of the demand for a new alternative, but do not contain enough detail to model the demand for alternatives with different attribute levels or under different scenarios. Also, a very simple type of choice question may not be sufficient to get respondents to consider their likely choice behavior very carefully.

**Stated Tolerance**: Techniques included in this class do not ask respondents to respond to alternative behavioral outcomes represented by specific attributes and attribute levels. Instead, respondents are asked to identify the conditions under which they would take a particular action or accept a particular behavioral outcome. The basic type of information sought is responses to questions such as: “Under what circumstances could you imagine yourself doing the following?” One form of this approach that received much attention in transportation planning in the 1980’s was the “transfer price” (TP) method. The respondent would consider two choice alternatives, and then be asked to imagine that the cost of one of the alternatives changes and indicate at what level he or she would switch to the other alternative. For example, auto commuters could be asked to consider their best transit option and indicate how high fuel prices would have to rise before they would switch to commuting by transit. This method thus gives a direct quantitative measure of the difference in utility between two alternatives, but it has been questioned whether or not travelers can respond very accurately to such questions. A related method that is popular in the field of environmental economics is that of “contingent valuation” (CV), in which people are asked to directly value a “good” that is not actually available for purchase. For example, people can be asked how much they would be willing to pay in additional taxes if it could ensure that everyone in their city has access to good public transportation. This could be thought of in the context of stated tolerance—how much of such a tax would people be willing to tolerate?

**Stated Adaptation**: Techniques included in this class ask respondents to indicate in a relatively open-ended manner how they would respond when faced with a particular set of constraints. The basic type of information sought are responses to questions such as: “What would you do differently if you were faced with the following specific constraints?”

**Stated Prospect**: With these techniques, neither the list of possible behavioral outcomes nor a detailed set of constraints is predetermined. Instead, respondents are typically presented with some sort of general scenario (e.g., an energy shortage) as a way of initiating the process of eliciting behavioral outcomes and constraints. Measurement methods for these techniques involve the use of simulation gaming techniques. The basic type of information sought are responses to questions such as: “Under what circumstances would you be likely to change your travel behavior and how would you go about it?”

Of the classes of SR techniques, SP surveys are the most important source of data for developing a Discrete Choice Model (DCM) to represent traveler decisions when faced with new travel alternatives and transportation policy actions. DCMs have played an important role in transportation modeling for the last 25 years. “They are namely used to provide a detailed representation of the complex aspects of transportation demand, based on strong theoretical justifications” (Bierlaire, 1997).

In this Chapter of the Travel Survey Manual we focus on SP experiments. In the following section the design and deployment of the experiments is explained focusing on the attributes and their levels as well as the media and the way to present the choices to the respondents. The next section presents the main analysis that can be conducted through the calibration of DCMs based on SP information.

## Designing SP Experiments
The design of SP experiments involves the following stages:

- Designing the experiment in terms of the alternatives and attribute levels;
- Choosing a media;
- Defining the context for the exercise; and
- Designing the sampling plan.

These are each described in turn here now.

### Designing the Experiment in Terms of Alternatives and Attribute Levels

“An experiment defined in scientific terms involves the observation of the effect upon one variable, a response variable, given the manipulation of the levels of one or more other variables” (Hensher, et al., 2005). This is a general definition that can be applied to any science or field of research and to any problem that involves a stimulus and a response.

In developing an experimental design, the first step is to specify the types of choice alternatives, the choice attributes, and the attribute levels to be included in the analysis. Consider the example of a binary choice where the respondent is asked to choose between driving or riding a bus based on the following attributes:

- Travel time difference between the auto and the bus;
- Cost difference between the auto and the bus in percentage;
- Number of bus transfers.

In general, a minimum of three attributes is usually needed to provide a realistic context for the SP exercise. The attributes associated with a particular SP exercise should represent as much as possible those factors that are important in the choice process. Experience suggests that the number of attributes presented to a respondent should be limited to six or seven. Presenting respondents with more attributes makes the exercise increasingly difficult for respondents to deal with and may in some instances limit the usefulness of the data. (Note: Researchers tend to have different opinions in this regard, and some SP experiments have included over a dozen choice attributes—see Louviere, et al. (2000) for examples, and Jones and Bradley (2006) for further discussion.)

The classical approach, and the one that has been mostly used and tested to build these experiments, establishes attribute levels for the explanatory variables and then it uses these levels to build a design which is presented to the respondents.

The full factorial design that would result from all possible combinations of these levels most of the times results in too many choices. For instance if one defines three levels for each of the attributes described in the example above, the full factorial design would result in 3x3x3 = 27 different treatment combinations, too many to be answered by one respondent (Table 21.1).

#### Table 21.1 Full Factorial Design

A note should be given on the minimum number of levels to use for the attributes: a minimum of three levels is required to detect non-linear relationships between attributes and preferences. Therefore when non-linear relationships are thought to exist, at least three levels should be used.

There are several ways to reduce the number of different treatment combinations required. These include the following:

- Use “fractional-factorial” designs;
- Remove options that will “dominate” or be “dominated” by all other options in the choice set;
- Separate the alternatives into “blocks,” so that the full factorial design (or a larger fractional factorial)  is completed, with different groups of respondents each responding to a different subset of options; and
- Carry out a series of experiments with each individual, offering different attributes, but with at least one attribute common to all.

**Use of a fractional factorial design** - The approach to use a fractional orthogonal design can be done with many statistical software packages (SAS, SPSS, etc.). These computer programs search for a combination of the levels that result in 0 correlations between the attributes, known as the property of orthogonality, meaning independence between variables (Table 21.2). By guaranteeing that the attributes in the alternatives are uncorrelated onehelps to ensure that the effect of each attribute can be estimated as independently from the others as possible. (Recently, however, so-called “d-optimal” design approaches have been introduced, that are more statistically efficient than orthogonal designs under certain conditions. See Rose et al. (2008) and Bliemer and Rose (2008) for more details)

#### Table 21.2 Fractional Orthogonal Design

Orthogonality among the attributes allows estimating the main effects of one variable on choice, independently of the effects that the other variables may have. For instance in the Auto/Bus mode choice example, if the choices that are presented to the respondents had always the same level for Travel Time Difference and Cost Difference, meaning total collinearity between the two vectors, it would not be possible to estimate the main effect of each of these variables on choice, because one cannot distinguish if the response is given due to price or to one or the other attribute.(This problem tends to occur in RP data, as one does not control the attribute levels. Although perfect collinearity is very unlikely to appear in real life data,  correlations can sometimes be problematic, for instance travel time and travel distance can be highly correlated., )

While the fractional factorial approach can significantly reduce the number of treatments needed for a SP exercise, it typically does so by ignoring some or all interaction effects. If interactions among attributes are, in fact, significant, their effects will be loaded onto the individual main effects, while it will bias the estimate of the relative importance of individual attributes on response. The degree of bias will depend on the significance of the interaction effects. If this bias occurs, the main effects are said to be “confounded” with interaction effects. If interactions are expected to be important (e.g. the effect of real-time information for transit services may be highly related to the level of service frequency or waiting time), then a fractional design should be selected that allows unbiased estimation of those specific interaction terms.

**Removing Dominant/Dominated Options** - This approach applies primarily to SP exercises presented as choice experiments. With this approach, those choice alternatives that dominate or are dominated in each attribute by every other alternative included in the choice set can be excluded. The only potential drawback with this approach is that any respondents choosing alternatives at random or illogically will not be easily identified based on an analysis of their responses. Note that this approach can disrupt the orthogonality of the statistical design and introduce correlations between parameter estimates.

**Block Design** - Another approach involves dividing the total number of treatment combinations included in an experimental design into sub-sets (or blocks). The sample of respondents is randomly divided into groups, with each group receiving a different block.. This approach can be implemented by including the block number as an additional “attribute” in the design so that block membership is orthogonal to the choice attribute levels. In that way, each respondent will face all of the levels of the various choice attributes in a balanced way, which increases the efficiency of parameter estimation. Research by Hess, et al. (2008) has shown that the use of proper blocking of a large fractional factorial design is very important to ensure efficient parameter estimation.

**Common Attributes** - With this approach the attributes to be evaluated are divided among two or more experimental designs. At least one common attribute must appear in each design to allow comparison of relative preferences over all the attributes included. In practical examples, cost is often used as a common “linking” variable, since it has a metric, quantitative meaning that tends to be transferable across choice contexts. The issue of how best to divide the attributes into difference sets is mainly from the respondents’ point of view—which variables make the most sense to trade off versus one another. For example, if one wishes to evaluate many transit service attributes, then one could separate out the attributes related to the station/stop from those related to the trip inside the vehicle, using fare as a common linking attribute.

When generating choice sets via a factorial design, some alternatives that are generated may not be plausible and may affect the respondents’ confidence in the survey.. For instance,a respondent might find  a “+60%” cost difference between the auto and the bus mode to be strange and unrealistic when he usually drives very few minutes from home to work and has no parking expenses. The respondent may try to imagine that situation, but his routine experience may keep him from understanding the hypothetical situation.

A common solution is to create designs that are built (“pivoted”) around the actual reported experiences of the respondents (Hensher, 2004). This is done by using information gathered in an earlier stage, where the respondent is asked about hisactual experience and behavior (a RP observation), characterized in the same attributes which are latter used for the alternatives specification. (Rose et al., 2008) state that“The use of a respondent’s experience, embodied in a reference alternative, to derive the attribute levels of the experiment has come about in recognition of a number of supporting theories in behavioral and cognitive psychology, and economics, such as prospect theory, case based decision theory and minimum regret theory”  (They also warn, however, that care should be taken when using such customized designs in combination with d-optimal design approaches.)

### Choosing the Survey Media

Unless the SP exercise is very simple, some sort of visual presentation of the alternatives and attribute levels will be necessary in order to allow respondents to understand and comprehend what is being presented to them. This is particularly true for choice and rating exercises, in which the respondent must compare two or more alternatives. This would limit the usefulness of telephone interviews, unless the respondent has received survey materials in advance. Reading a large set of variables over the telephone would make it impossible for the respondent to memorize and compare the alternatives.

The format and layout of the instrument used for the exercise will depend to some extent on the type of response sought (i.e., choice, ranking or rating). For choice exercises, respondents will be comparing two or more alternatives at the same time. The alternatives comprising the choice set should appear together on a card, sheet of paper or computer screen. For ranking exercises, having each alternative on a separate card is very useful, since this approach allows the respondent to spread them out and physically arrange them in their order of preference however, this can also be done in a computer screen in more modern software. With rating data, it is usually only necessary to consider one alternative at a time independently from other alternatives. Therefore, a wide range of layouts are possible for these responses.

It is always useful and in some cases essential (e.g., when respondents are expected to complete the exercises on their own) to provide materials describing the alternatives, attributes, and attribute levels included in the exercise. This could include drawings or pictures of new travel modes (e.g., high-speed trains) or sample schedules and route maps for new transit services.

When SP designs are customized based on respondents’ actual reported choice situations, this approach can be handled most efficiently using computer-based technology because customized branching can obtain a clearer picture of each distinct respondent’s choices ; and then realistic alternative scenarios can be constructed to understand the respondent’s behavior. Although the survey itself is simple and straightforward for the respondent, there is significant behind-the-scenes programming used to resolve this complexity. The ability to survey respondents effectively using sophisticated methods allows the researcher to obtain the critical data he or she needs while making the survey experience simple and clear for the respondent.

One important advantage of computer-based surveys is the ability to immediately geocode the respondent’s origin and destination, and search databases to obtain realistic attribute levels for the O-D pair, allowing the construction of more realistic SP experiments for the respondent later in the survey (TRB, 2006)..

For many transit researchers, survey services are a very good solution to develop a survey at low cost and to learn firsthand about web-based surveys and how the process works. However, researchers often find that online services and generic survey software do not meet their needs. For example, longitudinal surveys cannot be created that track one respondent over time using such tools. Nor can SP surveys for mode choice studies be produced effectively using less expensive online survey services, although there is much more expensive software that does allow for advanced online mode choice surveys to be created. Features such as online geocoding and linking transit schedules are typically not incorporated into these surveys. Advanced validation cannot be accomplished, as these tools are not capable of, for example, comparing a zip code with a data table of zip codes to confirm if a respondent’s answer is an existing zip code or not. For general market research purposes, the most popular software for computer-based SP surveys is sold by Sawtooth Software. In the field of travel demand modeling, however, SP surveys are typically designed and fielded by consulting firms, often in collaboration with survey firms. In the US, Resource Systems Group has been conducting web-based SP surveys of travel behavior since the mid-1990’s.

### Defining the Context for the Exercise

A key objective in the design of SP exercises is to establish as much realism as possible. The following points noted by Jones (1989) are particularly relevant to building realism into the context of the exercise, the options that are presented and the responses that are permitted:

- Focus on very specific rather than general behavior- i.e., ask respondents how they would respond to a particular product or service under a specific set of conditions rather than in general;
- Use a realistic choice context that respondents have actually experienced or one that they feel they could be placed into;
- Use existing or realistic levels of attributes within the experimental design so that the alternatives are built around these levels;
- Limit the range over which attribute levels are varied to those values that respondents perceive to be possible;
- Wherever possible, incorporate checks on the answers given;
- Allow for the effect of day-to-day variability on choices;
- Make sure that all variables relevant to the choice process are included in the analysis;
- Where possible, simplify the presentation of choice exercises (e.g., by highlighting the attribute levels that are different between alternatives);
- Make sure that constraints on choice are taken into account (e.g., fixed arrival times at work); and
- Allow respondents to opt for a response outside the set of the experimental alternatives (e.g., in all alternatives in a mode choice exercise are too expensive, the respondent may choose not to make the trip, so “neither” should be included as a possible response).

Because of the nature of this type of survey where the respondent is asked to state his or her action according to attributes of alternatives which he or she has not perceived, it is extremely important to ask the right questions to not implicitly induce a specific answer.

The FHWA Travel Survey Manual (1996) provides some examples of confusing SP survey-related questions to avoid, and how they can be improved upon:

*Questions Outside Respondent’s Experience:*

Problem: “The agency is considering building a rail transit system similar to the one in Washington, DC.”

Improvement: “The agency is considering building a rail transit system.”

*Technical Terms:*

Problem: “Did you use an HOV lane for any part of your work trip?”

Improvement: “For any part of your trip from home to work, did you use a carpool lane that requires autos to have more than two people in them?”

*Uncommon Idiom:*

Problem: “With which mode did you make the trip?”

Improvement: “How did you get there?” List of modes provided by interviewer or questionnaire.

*Omit Names of Alternatives:*

Problem: “Under these circumstances would you choose to take the maglev system described above or would you choose to take the other alternative?”

Improvement: “Under these circumstances, would you choose to take choice A or choice B?”

*Vary Descriptions of Alternatives:*

Problem: A SP question refers to a two-page description of a proposed new mode developed by the equipment manufacturer, and asks respondents to select between it and the mode they use now for different combinations of travel times and costs.

Improvement: The description of the new mode should be minimized and well-balanced with positive and negative attributes. All alternatives should receive similar descriptions.

*Link Personalities to Questions:*

Problem: “Governor Williamson has proposed increases in transit service in the Mudville area. How do you fell about this proposal? Do you strongly agree, agree, disagree, or strongly disagree with it?”

Improvement: “How do you feel about the proposal to increase transit service in the Mudville are? Do you strongly agree, agree, disagree, or strongly disagree with it?”

*Link Institutions to Questions:*

Problem: “Please rate the bus service offered by the public transit agency, City Transit: excellent, good, fair, or poor?”

Improvement: “Please rate the bus service in your area. Is it excellent, good, fair or poor?”

### Designing the Sampling Plan





## Validity of Stated-Preference Results


## Combining Stated - and Revealed-Preference Data


## Discrete Choice Models (DCMs) and the Willingness to Pay (WTP)


## Examples


## Conclusions



Chapter 21 of the Travel Survey Manual focuses on SP experiments. The design and deployment of the experiments is explained focusing on the attributes and their levels as well as the media and the way to present the choices to the respondents. The chapter also presents the main analysis that can be conducted through the calibration of DCMs based on SP information.

## References

Bates, J., (1988). Econometric Issues in Stated-Preference Analysis. Journal of Transport Economics and Policy, XXII(1), 59-69.

Bates, J.J, M. Bradley, M. Wardman, A. Fowkes; H. Gunn and several others.(1987). The Value of Travel Time Saving. A report of research undertaken for the U.K. Department of Transport. Policy Journals. Newbury, UK, 1987.

Ben-Akiva, M. and Morikawa, T., (1990). Estimation of Switching Models from Revealed-Preferences and Stated Intentions. Transport Research 24A(6), 485-495.

Ben-Akiva, M. E. and Lerman, S. R., (1985). Discrete choice analysis: theory and application to travel demand, Cambridge.MIT Press.

Ben-Akva, M. , D. Bolduc, and M. Bradley. (1993). Estimation of travel choice models with randomly distributed values of time. Transportation Research Record. 1413: 88-97. Transportation Research Board, Washington, D.C.1993.

Ben-Akiva, M., M. Bradley, T. Morikawa, J. Benjamin, T. Novak, H. Oppewal and V. Rao. Combining revealed and stated preferences data. (1994) Marketing Letters. 5(2): 335-349. Springer, Amsterdam. 1994.

Bierlair, M. (1997) Discrete Choice Models. Available from: http://roso.epfl.ch/mbi/papers/discretechoice/paper.html. Access date: 11 October 2009.


Bliemer, M.C.J. and J.M. Rose (2008). “Construction of Experimental Designs for Mixed Logit Models Allowing For Correlation Across Choice Observations”. Paper presented at the Transportation Research Board Conference, Washington, DC, January 2008.

Bradley, M. and H. Gunn (1991). A stated preference analysis of values of travel time in the Netherlands.  Transportation Research Record. 1285. Transportation Research Record, Washington, D.C.1991.

Bradley, M. and Kroes, E. (1992), Forecasting Issues in Stated-Preference Research. Selected Readings in Transport Survey Methodolog. E. Ampt, A. Richardson and A. Meyburg. Melbourne, Eucalyptus Press. pp. 89-107.

Bradley, M and A. Daly. (1994). Estimation of logit choice models using mixed stated preference and revealed preference information. (1994). In Understanding Travel Behavior in an Era of Urban Change. P.Stopher and M.Lee-Gosselin Ed. Pergamon Press, Oxford, 1994..

Bradley, M. and J. Zmud. (2006) Validating Willingness to Pay Estimates for Tolled Facilities through Panel Survey Methods. Paper presented at the 11th International Conference on Travel Behavior Research. Kyoto.

Tierney et al., FHWA (1996). Travel Survey Manual. Cambridge Systematics, Inc., Cambridge, MA.

Lee-Gosselin, M. (1995) The Scope and Potential of Interactive Stated-Response Data Collection Methods. TRB’s Conference on Household Travel Surveys, Irvine, CA.

Hensher, D. A., (2004). Identifying the influence of stated choice design dimensionality on willingness to pay for travel time savings. Journal of Transport Economics and Policy, 38, 425-446.

Hensher, D. A., Rose, J. M. and Green, W. H., (2005). Applied Choice Analysis - A Primer, Cambridge.Cambridge University Press.


Hess, S., C. Smith, S. Falzarano, and J.Stubits (2008). “Measuring the Effects of Different Experimental Designs and Survey Administration Methods using an Atlanta Managed Lanes Stated Preference Survey”. Paper presented at the Transportation Research Board Conference, Washington, DC, January 2008

Jones, P. (1989) An Overview of Stated-Preference Techniques. (Note –this needs more details, Goncalo…)

Jones, P.M. and M. Bradley (2006). “Stated Preference Surveys: An Assessment” in Travel Survey Methods: Quality and Future Directions. P. Stopher and C. Stecher ed. Elsevier Science. .

Louviere, J.J., D.A. Hensher and J.D, Swait. (2000). Stated Choice Methods: Analysis and Applications. Cambridge Univ. Press.

Lu, H., Fowkes, A. S,. Wardman, M. R. (2006) “The influence of stated preference (SP) design on the incentive to bias in responses”. Paper presented at the European Transport Conference, Strasbourg, October 2006.

Pearmain, D., Swanson, J., Kroes, E. and Bradley, M., (1991). Stated-Preference Techniques: A Guide to Practice. Steer Davies Gleave and Hague Consulting Group.

Rose, J. M., Bliemer, M. C. J., Hensher, D. A. and Collins, A. T., (2008). Designing efficient stated choice experiments in the presence of reference alternatives. Transportation Research Part B, 42(4), 395-406.

Sawtooth Software http://www.sawtoothsoftware.com/

Train, K. E., (2002). Discrete Choice Methods with Simulation.Cambridge University Press.

TRB (2006). Web-Based Survey Techniques. to be completed

The [Online Travel Survey Manual](Online_Travel_Survey_Manual) provides a comprehensive overview of travel surveys. It is curated by Transportation Research Board’s Travel Survey Methods Committee (ABJ40).


